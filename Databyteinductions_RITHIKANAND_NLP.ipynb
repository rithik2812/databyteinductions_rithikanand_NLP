{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fef25a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "800ff434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "                                                   0\n",
      "0  0,0.64,0.64,0,0.32,0,0,0,0,0,0,0.64,0,0,0,0.32...\n",
      "1  0.21,0.28,0.5,0,0.14,0.28,0.21,0.07,0,0.94,0.2...\n",
      "2  0.06,0,0.71,0,1.23,0.19,0.19,0.12,0.64,0.25,0....\n",
      "3  0,0,0,0,0.63,0,0.31,0.63,0.31,0.63,0.31,0.31,0...\n",
      "4  0,0,0,0,0.63,0,0.31,0.63,0.31,0.63,0.31,0.31,0...\n",
      "Dataset shape: (4601, 1)\n"
     ]
    }
   ],
   "source": [
    "file_path = 'spambase.csv'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "print(\"Dataset structure:\")\n",
    "print(data.head())\n",
    "print(f\"Dataset shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c15fcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features is: 57\n"
     ]
    }
   ],
   "source": [
    "X = data.apply(lambda row: pd.Series([float(x) for x in row[0].split(',')]), axis=1)\n",
    "y = X.iloc[:, -1] \n",
    "X = X.iloc[:, :-1]\n",
    "num_features = X.shape[1]\n",
    "print(f\"The number of features is: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32b53394",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daf8213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54fb033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.813, Precision: 0.680, Recall: 0.952, F1-score: 0.793\n",
      "Confusion Matrix:\n",
      "[[629 233]\n",
      " [ 25 494]]\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "pred_nb = nb_classifier.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, pred_nb)\n",
    "precision_nb = precision_score(y_test, pred_nb, average='binary', zero_division=1)\n",
    "recall_nb = recall_score(y_test, pred_nb, average='binary', zero_division=1)\n",
    "f1_nb = f1_score(y_test, pred_nb, average='binary', zero_division=1)\n",
    "cm_nb = confusion_matrix(y_test, pred_nb)\n",
    "\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_nb:.3f}, Precision: {precision_nb:.3f}, Recall: {recall_nb:.3f}, F1-score: {f1_nb:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "032263dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.928, Precision: 0.927, Recall: 0.920, F1-score: 0.923\n",
      "Confusion Matrix:\n",
      "[[822  40]\n",
      " [ 59 460]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "pred_lr = lr_classifier.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, pred_lr)\n",
    "precision_lr = precision_score(y_test, pred_lr, average='macro', zero_division=1)\n",
    "recall_lr = recall_score(y_test, pred_lr, average='macro', zero_division=1)\n",
    "f1_lr = f1_score(y_test, pred_lr, average='macro', zero_division=1)\n",
    "conf_matrix_lr = confusion_matrix(y_test, pred_lr)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {accuracy_lr:.3f}, Precision: {precision_lr:.3f}, Recall: {recall_lr:.3f}, F1-score: {f1_lr:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_lr)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee6dae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines (SVM):\n",
      "Accuracy: 0.928, Precision: 0.925, Recall: 0.921, F1-score: 0.923\n",
      "Confusion Matrix:\n",
      "[[818  44]\n",
      " [ 55 464]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Support Vector Machines (SVM)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, pred_svm)\n",
    "precision_svm = precision_score(y_test, pred_svm, average='macro', zero_division=1)\n",
    "recall_svm = recall_score(y_test, pred_svm, average='macro', zero_division=1)\n",
    "f1_svm = f1_score(y_test, pred_svm, average='macro', zero_division=1)\n",
    "conf_matrix_svm = confusion_matrix(y_test, pred_svm)\n",
    "\n",
    "print(\"Support Vector Machines (SVM):\")\n",
    "print(f\"Accuracy: {accuracy_svm:.3f}, Precision: {precision_svm:.3f}, Recall: {recall_svm:.3f}, F1-score: {f1_svm:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_svm)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04c5659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam():\n",
    "    try:\n",
    "        input_text = entry_text.get()  #preprocess the input text\n",
    "        input_data = np.array([float(x) for x in input_text.split(',')]) #split and converting to float\n",
    "        \n",
    "        \n",
    "        if len(input_data) != X.shape[1]:\n",
    "            raise ValueError(\"Invalid input length\")\n",
    "        \n",
    "        \n",
    "        input_data_scaled = scaler.transform([input_data])  #standardization\n",
    "        \n",
    "        \n",
    "        prediction = svm_classifier.predict(input_data_scaled) #making prediction\n",
    "        \n",
    "        # Display prediction\n",
    "        if prediction[0] == 1:\n",
    "            result_label.config(text=\"Prediction: Spam\")\n",
    "        else:\n",
    "            result_label.config(text=\"Prediction: Ham(not spam)\")\n",
    "    except ValueError as e:\n",
    "        messagebox.showerror(\"Error\", str(e))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab005f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Email Spam Classification\")\n",
    "\n",
    "entry_label = tk.Label(window, text=\"Enter email content (57 comma-separated values):\") #found it was 57 by finding number of features\n",
    "entry_label.pack()\n",
    "\n",
    "entry_text = tk.Entry(window, width=60)\n",
    "entry_text.pack()\n",
    "\n",
    "predict_button = tk.Button(window, text=\"Predict\", command=predict_spam)\n",
    "predict_button.pack()\n",
    "result_label = tk.Label(window, text=\"\")\n",
    "result_label.pack()\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0490688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Anand'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ba75c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.017, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Building Naive Bayes Classifier without using any libraries\n",
    "\n",
    "def standard_scaler(X_train, X_test):\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    X_train_scaled = (X_train - mean) / std\n",
    "    X_test_scaled = (X_test - mean) / std\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "#calculating Gaussian probability density function\n",
    "def gaussian_probability(x, mean, std):\n",
    "    exponent = np.exp(-((x - mean)**2) / (2 * std**2))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "#training the model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    n_samples, n_features = X_train.shape\n",
    "    classes = np.unique(y_train)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # The class priors represent the probability of each class occurring in the dataset.\n",
    "    class_priors = {}\n",
    "    for c in classes:\n",
    "        class_priors[c] = np.sum(y_train == c) / float(n_samples)\n",
    "    \n",
    "    # Calculating mean and standard deviation for each feature in each class\n",
    "    parameters = {}\n",
    "    for c in classes:\n",
    "        X_c = X_train[y_train == c]\n",
    "        class_params = []\n",
    "        for feature in range(n_features):\n",
    "            mean = np.mean(X_c[:, feature])\n",
    "            std = np.std(X_c[:, feature])\n",
    "            class_params.append((mean, std))\n",
    "        parameters[c] = class_params\n",
    "    \n",
    "    return class_priors, parameters\n",
    "\n",
    "def predict_naive_bayes(X_test, class_priors, parameters):\n",
    "    predictions = []\n",
    "    for sample in X_test:\n",
    "        posteriors = {}\n",
    "        for c, params in parameters.items():\n",
    "            class_prior = class_priors[c]\n",
    "            likelihood = 1.0\n",
    "            for feature, (mean, std) in enumerate(params):\n",
    "                likelihood *= gaussian_probability(sample[feature], mean, std)\n",
    "            posterior = class_prior * likelihood\n",
    "            posteriors[c] = posterior\n",
    "        prediction = max(posteriors, key=posteriors.get)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / float(total)\n",
    "\n",
    "\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "X = data.apply(lambda row: pd.Series([float(x) for x in row[0].split(',')]), axis=1)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "X_train, X_test = standard_scaler(X_train, X_test)\n",
    "\n",
    "class_priors, parameters = train_naive_bayes(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_nb = predict_naive_bayes(X_test, class_priors, parameters)\n",
    "\n",
    "\n",
    "# calculating precision\n",
    "def precision_score(y_true, y_pred, pos_label=1):\n",
    "    true_positives = np.sum((y_true == pos_label) & (y_pred == pos_label))\n",
    "    predicted_positives = np.sum(y_pred == pos_label)\n",
    "    if predicted_positives == 0:\n",
    "        return 0  \n",
    "    return true_positives / float(predicted_positives)\n",
    "\n",
    "# Function to calculate recall\n",
    "def recall_score(y_true, y_pred, pos_label=1):\n",
    "    true_positives = np.sum((y_true == pos_label) & (y_pred == pos_label))\n",
    "    actual_positives = np.sum(y_true == pos_label)\n",
    "    if actual_positives == 0:\n",
    "        return 0 \n",
    "    return true_positives / float(actual_positives)\n",
    "\n",
    "# Function to calculate F1-score\n",
    "def f1_score(y_true, y_pred, pos_label=1):\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=pos_label)\n",
    "    if precision + recall == 0:\n",
    "        return 0 \n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Function to calculate confusion matrix\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    classes = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    cm = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    for i in range(len(classes)):\n",
    "        true_class = classes[i]\n",
    "        for j in range(len(classes)):\n",
    "            predicted_class = classes[j]\n",
    "            cm[i, j] = np.sum((y_true == true_class) & (y_pred == predicted_class))\n",
    "    return cm\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb, pos_label=1)\n",
    "recall_nb = recall_score(y_test, y_pred_nb, pos_label=1)\n",
    "f1_nb = f1_score(y_test, y_pred_nb, pos_label=1)\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_nb:.3f}, Precision: {precision_nb:.3f}, Recall: {recall_nb:.3f}, F1-score: {f1_nb:.3f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3905e610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Anand'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b28a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
